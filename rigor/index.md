---
title: iPQB_Rigor
layout: default
group: pubs
---

*iPQB Reproducibility and Rigor: Experimental Controls Module*

Introduction

- When you think of bias in an experiment, what comes to mind?
- What is an example of an unavoidable bias? What could be an example of an avoidable bias? An
intentionally introduced bias?
- With regard to preparing samples for an experiment, what might constitute bias on the part of
the experimenter? How might this type of bias manifest in the design of an experiment?
- How do you think bias might affect what is documented in a protocol, or detailed in a materials
and methods section?
- Do you think there is a component of laboratory and research culture that must be considered
when addressing reproducibility and rigor in research?
- Would people be willing to admit that their lab might not always conduct the most rigorously
designed studies?


#Biological and Technical Replicates#

{::nomarkdown}
<div class="video-container">
         <iframe src="//www.youtube.com/embed/wSWunBYzl8c" frameborder="0" width="280" height="107"></iframe>
</div>
<br>
{:/nomarkdown}

Starting Points:
- Replication: requires a precise process where the exact same findings are reexamined in the same way with identical design, power, subject selection requirements, and level of significance as the original research study.1
- Biological replicates are parallel measurements of biologically distinct samples that capture random biological variation, which may itself be a subject of study or a source of noise.
- Technical replicates are repeated measurements of the same sample that represent independent measures of the random noise associated with protocols or equipment.

Lead-in Questions:
- Within an individual experiment, what do you think is the best approach to determine the
appropriate number of replicates?
- How did you learn about the need for replicates and the difference between certain types of
replicates?

Follow-up Questions:
- Do you think it is common to report data from a single experiment (technical replicates) to generate an “exciting” finding? How often is this type of practice viewed as a way to expedite the research process?
- Since this is a grant application with preliminary results, is it acceptable to include results in such a manner?
- Is it appropriate for the applicant to purposely leave information about the type of replicates out and plot the data in such a way as to suggest significance over multiple experiments? Can it be considered falsification and therefore possible misconduct? If so, what are the potential consequences? What if it was simply an oversight?
- If this was your grant application, how would you have portrayed the data? Would you clearly state the “n” in the figure legend and/or describe this in the body of the grant? Would you have indicated the exclusion of data?
- Do you think papers or grant applications should delineate the use of biological vs. technical replicates in the figure legends (or elsewhere in the document)?
- The reviewer provides an analogy of “taking a thousand cells from one animal” and getting “just one point” from the resulting data. Is this always the case?3
- Do you think the review of the project will be affected?
- Do you think a typical review session discussing this issue would be as collegial?
- The reviewers appeared to be convinced easily that the figure was misleading. Do you think this transition in thought would have been so quick and painless if it were a real review session?
